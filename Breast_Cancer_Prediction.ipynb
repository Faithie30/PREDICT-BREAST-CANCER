{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # <b> Predict Breast Cancer<b>\n",
    "    \n",
    "    \n",
    "<b> Logistic Regression </b> is a Machine Learning classification algorithm that is used to predict the probability of a categorical dependent variable. In this asssignmet we will predict the class of breast cancer (malignant or ‘bad’ versus benign or ‘good’) from the features of images taken from breast samples. Ten biological attributes of the cancer cell nuclei have been calculated.\n",
    "\n",
    "<b> Table of Contents: </b>    \n",
    "1. Importing Packages\n",
    "2. Exploratory Data Analysis\n",
    "3. Feature selection\n",
    "4. Splitting the dataset into train and test sets\n",
    "5. Fitting a logistic regression model to the train set\n",
    "6. Making predictions and evaluating performance\n",
    "7. Classification report\n",
    "8. Receiver Operating Characteristic (ROC)\n",
    "7. Model Stability\n",
    "8. References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the required libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import statsmodels.api as sm\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Viewing dataset\n",
    "df = pd.read_csv('data/cancer.data', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis\n",
    "\n",
    "### 2.1 Inspecting for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Overview of the dataset\n",
    "df.info\n",
    "\n",
    "# converting the \"?\" values to NaN\n",
    "df = df.replace('?', np.nan)\n",
    "\n",
    "\n",
    "# filling in NaNs with the most frequent value from its column\n",
    "for col in df:\n",
    "    if df[col].dtype == 'object':\n",
    "        df = df.fillna(df[col].value_counts().index[0])\n",
    "        \n",
    "#dropping duplicates within the dataframe\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Renaming columns\n",
    "column_names = {0:'id number', 1:\"Clump Thickness\", 2:\"Uniformity of Cell Size\", 3:\"Uniformity of Cell Shape\", 4: \"Marginal Adhesion\", 5:\"Single Epithelial Cell Size\",\n",
    "              6:\"Bare Nuclei\", 7:\"Bland Chromatin\", 8:\"Normal Nucleoli\", 9:\"Mitosesi\", 10:\"Class\"}\n",
    "df = df.rename(columns=column_names)\n",
    "\n",
    "\n",
    "# converting the non integer values to integers\n",
    "df[\"Bare Nuclei\"] = df[\"Bare Nuclei\"].replace(\"?\", 0) \n",
    "df[\"Bare Nuclei\"] = df[\"Bare Nuclei\"].astype(\"int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Droping the ID and Class columns and convert the DataFrame to a NumPy array\n",
    "df = df.drop(columns = df.columns[0], axis=1)\n",
    "\n",
    "\n",
    "#Inspecting the object values\n",
    "df['Bare Nuclei'].value_counts()\n",
    "\n",
    "\n",
    "# Converting Class entries to binary\n",
    "df['Class'] = df['Class'].replace([2,4], [1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating dummy variables\n",
    "\n",
    "l_e =  LabelEncoder()\n",
    "for col in df:\n",
    "      if df[col].dtypes =='object':\n",
    "        df[col]=l_e.fit_transform(df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_profiling import ProfileReport\n",
    "#----------------------------------------------------------------------------------------------------------\n",
    "\n",
    "profile = ProfileReport(df, title='Pandas Profiling Report', html={'style':{'full_width':True}})\n",
    "\n",
    "#Saving profile report into an html file titled dataset_report\n",
    "profile.to_file(output_file=\"dataset_report.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature selection\n",
    "\n",
    "The stats model regression model will be used to select the features looking at the p-value which shows the significance of each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data descriptives\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x = 'Class',data = df);\n",
    "\n",
    "df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection for model\n",
    "sns.heatmap(df.corr());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <b> correlation scores </b>  above prove that there is signifance in the impact of the following variables towards predicting malignant cancer:\n",
    "\n",
    "- Clump Thickness               -0.716001\n",
    "- Uniformity of Cell Size       -0.817904\n",
    "- Uniformity of Cell Shape      -0.818934\n",
    "- Marginal Adhesion             -0.696800\n",
    "- Single Epithelial Cell Size   -0.682785\n",
    "- Bare Nuclei                   -0.817653\n",
    "- Bland Chromatin               -0.756616\n",
    "- Normal Nucleoli               -0.712244\n",
    "\n",
    "All of the feautures above represent Negative-Strong Relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Hypothesis Testing</b>\n",
    "\n",
    "Null hypthesis (H0) : The feature variables do not have a significant effect on the response variable \n",
    "\n",
    "Alternative Hypothesis (H1) : The at least one of the feature variables have a significant effect on the response variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding constant column \n",
    "X1 = sm.add_constant(X)\n",
    "\n",
    "#Fitting sm.OLS model\n",
    "model = sm.OLS(y,X1).fit()\n",
    "model.pvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pvalues above prove that there is signifance in the impact of the following variables towards predicting malignant cancer:\n",
    "\n",
    "Clump Thickness:                  2.791906e-18 <br>\n",
    "Uniformity of Cell Size:          5.462468e-04 <br>\n",
    "Uniformity of Cell Shape:        6.308670e-03 <br>\n",
    "Marginal Adhesion:                1.596158e-01 <br>\n",
    "Single Epithelial Cell Size:      1.713468e-01 <br>\n",
    "Bare Nuclei:                      9.192607e-42 <br>\n",
    "Bland Chromatin:                  4.296908e-05 <br>\n",
    "Normal Nucleoli:                  2.422993e-06 <br>\n",
    "\n",
    "All of the pvalues that are presented above are all <0.05, therefore we reject the null hypothesis these features have a signifcant relationship efffect on predicting malignant cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Spliting data into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# segregate features and lables into separate variables\n",
    "X= df.drop(['Class'], axis=1)\n",
    "y=df['Class']\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming the Features\n",
    "X,y = df.drop('Class', axis = 1) , df['Class']\n",
    "\n",
    "# Instantiate MinMaxScaler and use it to rescale X_train and X_test\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "rescaledX_train = scaler.fit_transform(X_train)\n",
    "rescaledX_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Fitting a logistic regression model to the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a model\n",
    "model = LogisticRegression()\n",
    "\n",
    "#fitting the log regression to train set\n",
    "model.fit(rescaledX_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Making predictions and evaluating performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confussion matrix\n",
    "predict_model = model.predict(rescaledX_test)\n",
    "pred_model = model.predict(rescaledX_train)\n",
    "labels = ['Malignant','Benign']\n",
    "\n",
    "#Confusion matrix for test data\n",
    "pd.DataFrame(data=confusion_matrix(predict_model, y_test), index=labels, columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrix for training data\n",
    "pd.DataFrame(data=confusion_matrix(pred_model, y_train), index=labels, columns=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The confusion matrix for the test data  shows:\n",
    "\n",
    "- 62+141 correct predictions\n",
    "- 2 + 5 incorrect predictions\n",
    "\n",
    "#### The confusion matrix for the train data shows:\n",
    "\n",
    "- 165+308 correct predictions\n",
    "- 7+9 incorrect predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification report\n",
    "\n",
    "print('\\nTest dataset-------------------------------------------')\n",
    "print(classification_report(y_test, predict_model))\n",
    "print('\\nTrain dataset------------------------------------------')\n",
    "print(classification_report(y_train, pred_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following calaculations are analysis made based on the above confusion matrix.\n",
    "\n",
    "<b>Accuracy:</b>\n",
    "Overall, how often is the classifier correct?\n",
    "- Accuracy = TP+TN/(TP+TN+FN+FP)\n",
    "\n",
    "<b>Precision:</b>\n",
    "When it predicts begnin, how often is it correct?\n",
    "- Precision= TP/(TP+FP)\n",
    "\n",
    "<b>Recall:</b>\n",
    "When it's actually begnin, how often does it predict begnin?\n",
    "- Recall= TP/(TP+FN)\n",
    "\n",
    "<b>F1-score:</b>\n",
    "This is a weighted average of the true positive rate (recall) and precision\n",
    "- F1_score = (2*Recall*Precision)/(Precision+Recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Receiver Operating Characteristic (ROC)\n",
    "\n",
    "This is a commonly used graph that summarizes the performance of a classifier over all possible thresholds. It is generated by plotting the True Positive Rate (y-axis) against the False Positive Rate (x-axis) as you vary the threshold for assigning observations to a given class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "logreg_roc_auc = roc_auc_score(y_test, predict_model)\n",
    "fpr, tpr, threshold_log = roc_curve(y_test, predict_model)\n",
    "\n",
    "plt.plot(fpr, tpr, color='green', label=f'ROC = {logreg_roc_auc}')\n",
    "plt.plot([0, 1], [0, 1], color='purple', linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Model Stability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The further the curve is from the diagonal line, the better the model is at discriminating between positives and negatives in general. In our case the model gets to 0.955 True Positive Rate before the rate of False positive starts increasing rapidly.\n",
    "\n",
    "Overdispersion occurs when error (residuals) are more variable than expected from the theorized distribution. In case of logistic regression, the theorized error distribution is the binomial distribution. The variance of binomial distribution is a function of its mean (or the parameter p). If there is overdispersion, the coeﬃcient estimates will be more conﬁdent (smaller standard error values) than they should be. One can detect overdispersion by comparing the residual deviance with the degrees of freedom. If these two numbers are close, there is no overdispersion\\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/building-a-logistic-regression-in-python-step-by-step-becd4d56c9c8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.system('jupyter nbconvert --to html Breast_Cancer_Prediction.ipynb')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
